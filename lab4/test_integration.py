#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºçš„éª¨æ¶æ•°æ®å¤„ç†æ¨¡å—ä¸ç°æœ‰è®­ç»ƒæµæ°´çº¿çš„é›†æˆ
"""

import os
import torch
from skeleton_utils import EnhancedSkeletonDataset

def test_enhanced_dataset():
    """æµ‹è¯•å¢å¼ºæ•°æ®é›†çš„åŸºæœ¬åŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯•å¢å¼ºéª¨æ¶æ•°æ®é›†")
    print("=" * 60)
    
    # æ‰¾åˆ°CSVæ–‡ä»¶
    data_dir = "skeleton"
    csv_files = [os.path.join(data_dir, f) 
                 for f in os.listdir(data_dir) 
                 if f.lower().endswith(".csv")]
    
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        return False
        
    print(f"âœ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    # æµ‹è¯•æ— å¢å¼ºçš„æ•°æ®é›†
    print("\n1. æµ‹è¯•åŸºç¡€æ•°æ®é›† (æ— å¢å¼º)...")
    try:
        basic_ds = EnhancedSkeletonDataset(csv_files[:2])
        print(f"âœ“ åŸºç¡€æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"  - æ ·æœ¬æ•°é‡: {len(basic_ds)}")
        print(f"  - ç‰¹å¾ç»´åº¦: {basic_ds.feature_dim}")
        print(f"  - æœ€å¤§åºåˆ—é•¿åº¦: {basic_ds.max_len}")
        
        # æµ‹è¯•è·å–å•ä¸ªæ ·æœ¬
        sample, label = basic_ds[0]
        print(f"  - ç¬¬ä¸€ä¸ªæ ·æœ¬å½¢çŠ¶: {sample.shape}")
        print(f"  - ç¬¬ä¸€ä¸ªæ ·æœ¬æ ‡ç­¾: {label}")
        
    except Exception as e:
        print(f"âŒ åŸºç¡€æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•å¸¦å¢å¼ºçš„æ•°æ®é›†
    print("\n2. æµ‹è¯•å¢å¼ºæ•°æ®é›†...")
    try:
        augmentation_config = {
            'noise_std': 0.02,
            'time_stretch_range': [0.8, 1.2],
            'spatial_scale_range': [0.9, 1.1],
            'rotation_angle_deg': 15.0,
            'crop_ratio': 0.1
        }
        aug_ds = EnhancedSkeletonDataset(csv_files[:2], augmentation_config=augmentation_config)
        print(f"âœ“ å¢å¼ºæ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"  - æ ·æœ¬æ•°é‡: {len(aug_ds)}")
        print(f"  - ç‰¹å¾ç»´åº¦: {aug_ds.feature_dim}")
        
        # æµ‹è¯•å¤šæ¬¡è·å–åŒä¸€æ ·æœ¬ï¼ŒéªŒè¯å¢å¼ºçš„éšæœºæ€§
        sample1, _ = aug_ds[0]
        sample2, _ = aug_ds[0]
        
        if torch.equal(sample1, sample2):
            print("  âš ï¸  è­¦å‘Š: å¢å¼ºå¯èƒ½æœªç”Ÿæ•ˆï¼Œä¸¤æ¬¡è·å–ç›¸åŒæ ·æœ¬ç»“æœç›¸åŒ")
        else:
            print("  âœ“ æ•°æ®å¢å¼ºæ­£å¸¸å·¥ä½œ (ç›¸åŒç´¢å¼•è¿”å›ä¸åŒç»“æœ)")
            
    except Exception as e:
        print(f"âŒ å¢å¼ºæ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•DataLoaderå…¼å®¹æ€§
    print("\n3. æµ‹è¯•DataLoaderå…¼å®¹æ€§...")
    try:
        dataloader = torch.utils.data.DataLoader(
            basic_ds, batch_size=4, shuffle=True
        )
        
        batch_x, batch_y = next(iter(dataloader))
        print(f"âœ“ DataLoaderå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        print(f"  - æ‰¹æ¬¡è¾“å…¥å½¢çŠ¶: {batch_x.shape}")
        print(f"  - æ‰¹æ¬¡æ ‡ç­¾å½¢çŠ¶: {batch_y.shape}")
        
    except Exception as e:
        print(f"âŒ DataLoaderå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¢å¼ºæ•°æ®é›†é›†æˆæˆåŠŸ")
    print("=" * 60)
    return True

def test_csv_parsing():
    """æµ‹è¯•CSVè§£æçš„è¯¦ç»†ä¿¡æ¯"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•CSVè§£æè¯¦æƒ…")
    print("=" * 60)
    
    from skeleton_utils import SkeletonCSVParser
    
    # æ‰¾åˆ°ä¸€ä¸ªCSVæ–‡ä»¶è¿›è¡Œè¯¦ç»†æµ‹è¯•
    data_dir = "skeleton"
    csv_files = [os.path.join(data_dir, f) 
                 for f in os.listdir(data_dir) 
                 if f.lower().endswith(".csv")]
    
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        return False
    
    csv_file = csv_files[0]
    print(f"æµ‹è¯•æ–‡ä»¶: {os.path.basename(csv_file)}")
    
    try:
        parser = SkeletonCSVParser()
        data, metadata = parser.parse_csv(csv_file)
        
        print(f"âœ“ CSVè§£ææˆåŠŸ")
        print(f"  - æ•°æ®å½¢çŠ¶: {data.shape}")
        print(f"  - å…ƒæ•°æ®:")
        for key, value in metadata.items():
            if isinstance(value, list) and len(value) > 5:
                print(f"    {key}: [{len(value)} items] {value[:3]}...")
            else:
                print(f"    {key}: {value}")
                
    except Exception as e:
        print(f"âŒ CSVè§£æå¤±è´¥: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = True
    success &= test_csv_parsing()
    success &= test_enhanced_dataset()
    
    if success:
        print("\nğŸ‰ é›†æˆæµ‹è¯•å®Œå…¨æˆåŠŸï¼å¯ä»¥å¼€å§‹ä½¿ç”¨å¢å¼ºçš„æ•°æ®å¤„ç†æµæ°´çº¿ã€‚")
    else:
        print("\nğŸ’¥ é›†æˆæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")
